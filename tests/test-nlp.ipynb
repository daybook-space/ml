{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_filename = \"journals/journal-qualcomm.txt\"\n",
    "\n",
    "EVENT_TYPE = enums.Entity.Type.EVENT\n",
    "PERSON_TYPE = enums.Entity.Type.PERSON\n",
    "LOCATION_TYPE = enums.Entity.Type.LOCATION\n",
    "OTHER_TYPE = enums.Entity.Type.OTHER\n",
    "\n",
    "ALLOWABLE_LABELS = [enums.DependencyEdge.Label.DOBJ,\n",
    "                    #enums.DependencyEdge.Label.NSUBJ,\n",
    "                    #enums.DependencyEdge.Label.NSUBJPASS,\n",
    "                    enums.DependencyEdge.Label.IOBJ,\n",
    "                    enums.DependencyEdge.Label.POBJ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_words = \"generic_words.txt\"\n",
    "\n",
    "with open(generic_words) as f:\n",
    "    DISALLOWED_WORDS = set(f.read().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = language.LanguageServiceClient()\n",
    "\n",
    "with open(journal_filename, 'r') as journal_file:\n",
    "    # Instantiates a plain text document.\n",
    "    content = journal_file.read()\n",
    "\n",
    "document = types.Document(\n",
    "    content=content,\n",
    "    type=enums.Document.Type.PLAIN_TEXT)\n",
    "annotations = client.analyze_entity_sentiment(document=document, encoding_type=\"UTF8\")\n",
    "syntax = client.analyze_syntax(document=document, encoding_type=\"UTF8\")\n",
    "sentiment = client.analyze_sentiment(document=document, encoding_type=\"UTF8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sm_fun(score, magnitude):\n",
    "    return (expit(score * 10) - 0.5) * 2 * magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_label_map = {tok.text.begin_offset: tok.dependency_edge.label for tok in syntax.tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "people = []\n",
    "locations = []\n",
    "other = []\n",
    "\n",
    "for keyword in annotations.entities:\n",
    "    word_type = keyword.type\n",
    "    entity_obj = (keyword.name, keyword.sentiment.score, keyword.sentiment.magnitude)\n",
    "    if keyword.name in DISALLOWED_WORDS:\n",
    "        continue\n",
    "    \n",
    "    if keyword.type == EVENT_TYPE:\n",
    "        events.append(entity_obj)\n",
    "    \n",
    "    elif keyword.type == PERSON_TYPE:\n",
    "        people.append(entity_obj)\n",
    "    \n",
    "    elif keyword.type == LOCATION_TYPE:\n",
    "        locations.append(entity_obj)\n",
    "    \n",
    "    elif keyword.type == OTHER_TYPE:\n",
    "        allowable = False\n",
    "        \n",
    "        for mention in keyword.mentions:\n",
    "            content = mention.text.content\n",
    "            offset = mention.text.begin_offset\n",
    "            \n",
    "            for word in content.split(\" \"):\n",
    "                try:\n",
    "                    if offset_label_map[offset] in ALLOWABLE_LABELS:\n",
    "                        allowable = True\n",
    "                except:\n",
    "                    print(\"Missed word somehow\")\n",
    "                offset += (len(word) + 1)\n",
    "        \n",
    "        if allowable:\n",
    "            other.append(entity_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_items(items):\n",
    "    done = [False] * len(items)\n",
    "    new_items = []\n",
    "    \n",
    "    for i, item in enumerate(items):\n",
    "        if done[i]:\n",
    "            continue\n",
    "        done[i] = True\n",
    "        name = set(item[0].split(\" \"))\n",
    "        sum_1 = item[1]\n",
    "        sum_2 = item[2]\n",
    "        for j, i2 in enumerate(items):\n",
    "            if done[j]:\n",
    "                continue\n",
    "            ns = set(i2[0].split(\" \"))\n",
    "            if name & ns:\n",
    "                done[j] = True\n",
    "                sum_1 += i2[1]\n",
    "                sum_2 += i2[2]\n",
    "        \n",
    "        new_items.append((item[0], sum_1, sum_2))\n",
    "    \n",
    "    return new_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = collapse_items(events)\n",
    "people = collapse_items(people)\n",
    "locations = collapse_items(locations)\n",
    "other = collapse_items(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.sort(key=lambda x: -sm_fun(x[1], x[2]))\n",
    "people.sort(key=lambda x: -sm_fun(x[1], x[2]))\n",
    "locations.sort(key=lambda x: -sm_fun(x[1], x[2]))\n",
    "other.sort(key=lambda x: -sm_fun(x[1], x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(f'{i[0]}: {sm_fun(i[1], i[2])}') for i in events];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guy: 0.0\n",
      "Mason: 0.0\n"
     ]
    }
   ],
   "source": [
    "[print(f'{i[0]}: {sm_fun(i[1], i[2])}') for i in people];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Diego: 0.5430889802299089\n"
     ]
    }
   ],
   "source": [
    "[print(f'{i[0]}: {sm_fun(i[1], i[2])}') for i in locations];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answering problems: 0.899777865874302\n",
      "internship: 0.0\n"
     ]
    }
   ],
   "source": [
    "[print(f'{i[0]}: {sm_fun(i[1], i[2])}') for i in other];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "magnitude: 2.9000000953674316\n",
       "score: 0.5"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.document_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8611815587300202"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_fun(sentiment.document_sentiment.score, sentiment.document_sentiment.magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
